---
title: "4. Биномиальные доверительные интервалы"
author: "Г. Мороз"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.height = 3)
```

<style>
.parallax {
    /* The image used */
    background-image: url("4_conf.png");

    /* Set a specific height */
    min-height: 350px; 

    /* Create the parallax scrolling effect */
    background-attachment: fixed;
    background-position: center;
    background-repeat: no-repeat;
    background-size: auto;
}
</style>

<div class="parallax"></div>

### 1. Введение

* ваши данные состоят их множества биномиальных исходов
    * правильные vs. неправильные ответы у группы людей
    * диалектные vs. недеалектные формы у информантов
    * употребление предлога _в_ vs. остальные слова в группе текстов
    * ...

* Какая доля в среднем?
* Какая доля у каждой единицы наблюдения?
    * доля правильных ответов у каждого человека
    * доля диалектных форм у каждого информанта
    * доля употреблений предлога _в_ в каждом тексте
* How much uncertainty is present in our point estimate?

#### 1.1 Библиотеки
```{r}
library(tidyverse)
library(bootstrap)
library(mosaic)
```

#### 1.2 Рассказы А. Чехова
```{r}
chekhov <- read_tsv("https://goo.gl/o18uj7")
chekhov %>% 
  mutate(trunc_titles = str_trunc(titles, 25, side = "right")) ->
  chekhov
head(chekhov)
```
```{r, include=FALSE}
n_novels <- length(unique(chekhov$titles))
n_word <- length(unique(chekhov$word))
```

* `r n_novels` рассказов А. Чехова
* число слов в каждом рассказе
* `r n_word` уникальных слов в каждом рассказе

<div class="parallax"></div>

### 2. Averaging
```{r}
chekhov %>% 
  mutate(average = n/n_words) %>% 
  arrange(desc(average))  ->
  chekhov

chekhov %>% 
  select(trunc_titles, word, average)
```

Давайте посмотрим только на частицу _не_:

```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')
```

#### 2.1 Grand mean
```{r}
chekhov %>% 
  filter(word == "не") %>% 
  summarise(g_mean = mean(average)) ->
  grand_mean
grand_mean
```

```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')+
  geom_vline(xintercept = unlist(grand_mean), lty = 2)
```

#### 2.2 Trimmed mean
```{r}
chekhov %>% 
  filter(word == "не") %>% 
  summarise(t_mean = mean(average, trim = 0.05)) ->
  trimmed_mean
trimmed_mean
```

```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')+
  geom_vline(xintercept = unlist(trimmed_mean), lty = 2)
```

#### 2.3 Weighted mean
```{r}
chekhov %>% 
  filter(word == "не") %>% 
  summarise(w_mean = weighted.mean(average, n_words)) ->
  weighted_mean
weighted_mean
```

```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')+
  geom_vline(xintercept = unlist(weighted_mean), lty = 2)
```

<div class="parallax"></div>

### 3. Хакерский метод: бутстрэп

Из наших данных возьмем 10000 выборок с повторением.

```{r}
set.seed(42)
chekhov %>% 
  filter(word == "не") ->
  chekhov_bs

chekhov_bs <- bootstrap(chekhov_bs$average, nboot = 10000, theta = mean)$thetastar

# ggplot работает только с датафреймами
chekhov_bs <- data_frame(means = chekhov_bs)  

chekhov_bs %>% 
  ggplot(aes(means)) +
  geom_histogram(fill = "lightblue")+
  theme_bw()+
  labs(title = 'Средняя доля слова "не" на основе 305 рассказов А. Чехова', subtitle = "На основе 10000 бутстрэп-подвыборок")

chekhov_bs %>%
  summarise(mean = mean(means),
            q1 = quantile(means, 0.025),
            q2 = quantile(means, 0.975))->
  chekhov_stats
chekhov_stats

chekhov_bs %>% 
  ggplot(aes(means)) +
  geom_histogram(fill = "lightblue")+
  theme_bw()+
  labs(title = 'Средняя доля слова "не" на основе 305 рассказов А. Чехова', subtitle = "Среднее и 95% бутстрэпнутый доверительный интервал на основе 10000 бутстрэп-подвыборок")+
  geom_vline(xintercept = unlist(chekhov_stats), lty = c(2, 3, 3))
```

<div class="parallax"></div>

### 4. Фриквентисткий метод: доверительный интервал
Основная соль фриквинтистского доверительного интервала (по-английски confidence interval) основано на правиле трех сигм нормального распределения:

```{r, echo = FALSE, fig.height= 2.5}
ggplot(data.frame(x = 0:1), aes(x)) + 
        stat_function(fun = dnorm, args = c(0, 1), geom = 'area', xlim = c(-3, 3), fill = 'deepskyblue4') + 
      stat_function(fun = dnorm, args = c(0, 1), geom = 'area', xlim = c(-2, 2), fill = 'cadetblue') + 
    stat_function(fun = dnorm, args = c(0, 1), geom = 'area', xlim = c(-1, 1), fill = 'lightblue') + 
    stat_function(fun = dnorm, args = c(0, 1), xlim = c(-3, 3))+
  theme_bw()+
  geom_line(aes(y = c(0.15), x = c(-1, 1)), arrow = arrow(length=unit(0.2,"cm"), ends="both", type = "closed"))+
  geom_line(aes(y = c(0.03), x = c(-2, 2)), arrow = arrow(length=unit(0.2,"cm"), ends="both", type = "closed"))+
  annotate(geom = "text", x = 0, y = 0.17, label = "68.26%")+
  annotate(geom = "text", x = 0, y = 0.05, label = "95.44%")+
  scale_x_continuous(breaks = c(-3:3))+
  labs(y = "",
       x = "σ")
```

**z-score**:

* 95% данных находится в 1.96 стандартных отклонений
* 99% данных находится в 2.58 стандартных отклонений

Доверительный интервал:

* предположим что данные генеральной совокупности нормально распределены
* тогда доверительные интервалы выборок взятых из генеральной совокупности будут покрывать среднее генеральной совокупности

$$\bar{x} \pm z \times \frac{\sigma}{\sqrt{n}}\text{, где } z = 1 - \frac{\alpha}{2}$$

Распространение этой логики на биномиальные данные называется интервал Вальда:

$$\bar{x} = \theta; \sigma = \sqrt{\frac{\theta\times(1-\theta)}{n}}$$

Тогда интервал Вальда:

$$\theta \pm  z\times\sqrt{\frac{\theta\times(1-\theta)} {n}}$$

Есть только одна проблема: работает он плохо. Его аналоги перечислены в других работ:

* assymptotic method with continuity correction
* Wilson score
* Wilson Score method with continuity correction
* Jeffreys interval
* Clopper–Pearson interval (default in R `binom.test()`)
* Agresti–Coull interval
* ... см. пакет `binom`

```{r}
chekhov %>% 
  filter(word == "не") %>%
  slice(1:30) %>% 
  group_by(titles) %>% 
  mutate(low_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[1],
         up_ci = binom.test(x = n, n = n_words, ci.method = "Clopper-Pearson")$conf.int[2]) %>%
  ggplot(aes(trunc_titles, average))+
  geom_point()+
  geom_pointrange(aes(ymin = low_ci, ymax = up_ci))+
  theme_bw()+
  coord_flip()+
  labs(title = 'Среднее и 95% CI употребления "не" в рассказах А. Чехова',
       x = "", y = "")
```

<div class="parallax"></div>

### 5. Empirical Bayes estimation

Метод Empirical Bayes estimation -- один из байесовских методов, в рамках которого нужно:

*  произвести оценку априорного распределения вероятностей на основании имеющихся данных
* использовать полученное априорное распределение для получение апостериорной оценки для каждого наблюдения

Наши данные:
```{r}
chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_density(color = "red")+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова')
```

В данном случае, данные можно подогнать под бета распределение $Χ \sim Beta(α_0, β_0)$ (это далеко не всегда так). Подгонку можно осуществлять множеством разных функций, но я воспользуюсь следующей системой уравнений:

$$\mu = \frac{\alpha}{\alpha+\beta}$$
$$\sigma = \frac{\alpha\times\beta}{(\alpha+\beta)^2\times(\alpha+\beta+1)}$$

Из этой системы можно выразить $\alpha$ и $\beta$:

$$\alpha = \left(\frac{1-\mu}{\sigma^2} - \frac{1}{\mu}\right)\times \mu^2$$
$$\beta = \alpha\times\left(\frac{1}{\mu} - 1\right)$$

```{r}
mu <- mean(chekhov$average[chekhov$word == "не"])
var <- var(chekhov$average[chekhov$word == "не"])
alpha0 <- ((1 - mu) / var - 1 / mu) * mu ^ 2
beta0 <- alpha0 * (1 / mu - 1)
alpha0
beta0
```

Посмотрим, насколько хорошо, получившееся распределение подходит к нашим данным:
```{r}
x <- seq(0, 0.1, length = 1000)
estimation <- data_frame(
  x = x,
  density = c(dbeta(x, shape1 = alpha0, shape2 = beta0)))

chekhov %>% 
  filter(word == "не") %>% 
  select(trunc_titles, word, average) %>% 
  ggplot(aes(average)) +
  geom_histogram(fill = "lightblue")+
  geom_line(data = estimation, aes(x, density))+
  theme_bw()+
  labs(title = 'Частотность слова "не" на основе 305 рассказов А. Чехова',
       subtitle = "черной линией показано бета распределение с α = 5.283022 и β = 231.6328")
```

Полученное распределение можно использовать как априорное распределение. Этот трюк и называется Empirical Bayes estimation. 

<div class="parallax"></div>

### 6. Байесовский доверительный интервал
Байесовский доверительный $k$-% интервал (по-английски credible interval) --- это интервал $[\frac{k}{2}, 1-\frac{k}{2}]$ от апостериорного распределения. Давайте используем распределение, полученное в предыдущем разделе в качестве априорного для трдцети рассказов Чехова:

```{r}
chekhov %>% 
  filter(word == "не") %>%
  slice(1:30) %>% 
  group_by(titles) %>% 
  mutate(alpha_post = n+alpha0,
         beta_post = n_words-n+beta0,
         average_post = alpha_post/(alpha_post+beta_post),
         cred_int_l = qbeta(.025, alpha_post, beta_post),
         cred_int_h = qbeta(.975, alpha_post, beta_post)) ->
  posterior

posterior %>% 
  select(titles, n_words, average, average_post) %>% 
  arrange(n_words)

posterior %>% 
  ggplot(aes(titles, average_post, ymin = cred_int_l, ymax = cred_int_h))+
  geom_pointrange()+
  coord_flip()
```

```{r, echo= FALSE}
chekhov %>% 
  filter(word == "не") %>%
  slice(1:30) %>% 
  group_by(titles) %>% 
  mutate(low_ci = binom.test(x = n, n = n_words)$conf.int[1],
         up_ci = binom.test(x = n, n = n_words)$conf.int[2],
         interval = "confidence") %>% 
  ungroup() %>% 
  select(trunc_titles, low_ci, up_ci, interval)->
  df_1

chekhov %>% 
  filter(word == "не") %>%
  slice(1:30) %>% 
  group_by(titles) %>% 
  mutate(alpha_post = n+alpha0,
         beta_post = n_words-n+beta0,
         average_post = alpha_post/(alpha_post+beta_post),
         low_ci = qbeta(.025, alpha_post, beta_post),
         up_ci = qbeta(.975, alpha_post, beta_post),
         interval = "credible") %>% 
  ungroup() %>% 
  select(trunc_titles, low_ci, up_ci, interval)->
  df_2

rbind(df_1, df_2) %>% 
  ggplot(aes(trunc_titles, ymin = low_ci, ymax = up_ci, color = interval)) +
  geom_errorbar()+
  coord_flip()+
  theme_bw()
```



<div class="parallax"></div>